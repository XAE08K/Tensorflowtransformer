{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0640ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be1f8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                               with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e55f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Examples in Portuguese:\n",
      "os astrónomos acreditam que cada estrela da galáxia tem um planeta , e especulam que até um quinto deles tem um planeta do tipo da terra que poderá ter vida , mas ainda não vimos nenhum deles .\n",
      "agora aqui temos imagens sendo extraídas em tempo real diretamente do feed ,\n",
      "agora : um , dois , três , vai .\n",
      "\n",
      "> Examples in English:\n",
      "astronomers now believe that every star in the galaxy has a planet , and they speculate that up to one fifth of them have an earth-like planet that might be able to harbor life , but we have n't seen any of them .\n",
      "now here are live images being pulled straight from the feed .\n",
      "so : one , two , three , go .\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  print('> Examples in Portuguese:')\n",
    "  for pt in pt_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "  print()\n",
    "\n",
    "  print('> Examples in English:')\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f064fe",
   "metadata": {},
   "source": [
    "# Set up the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8570b26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c0be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8c82fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['detokenize',\n",
       " 'get_reserved_tokens',\n",
       " 'get_vocab_path',\n",
       " 'get_vocab_size',\n",
       " 'lookup',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaed3c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a batch of strings:\n",
      "astronomers now believe that every star in the galaxy has a planet , and they speculate that up to one fifth of them have an earth-like planet that might be able to harbor life , but we have n't seen any of them .\n",
      "now here are live images being pulled straight from the feed .\n",
      "so : one , two , three , go .\n"
     ]
    }
   ],
   "source": [
    "print('> This is a batch of strings:')\n",
    "for en in en_examples.numpy():\n",
    "  print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05280ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a padded-batch of token IDs:\n",
      "[2, 3946, 110, 321, 75, 198, 1452, 77, 71, 2662, 144, 37, 580, 13, 72, 83, 5848, 5939, 1970, 75, 130, 73, 103, 3339, 74, 124, 89, 111, 462, 14, 106, 580, 75, 242, 97, 264, 73, 3487, 183, 13, 87, 78, 89, 50, 9, 56, 464, 225, 74, 124, 15, 3]\n",
      "[2, 110, 137, 86, 301, 722, 222, 2404, 1473, 109, 71, 1559, 15, 3]\n",
      "[2, 82, 27, 103, 13, 165, 13, 218, 13, 164, 15, 3]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "\n",
    "print('> This is a padded-batch of token IDs:')\n",
    "for row in encoded.to_list():\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c220d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is human-readable text:\n",
      "astronomers now believe that every star in the galaxy has a planet , and they speculate that up to one fifth of them have an earth - like planet that might be able to harbor life , but we have n ' t seen any of them .\n",
      "now here are live images being pulled straight from the feed .\n",
      "so : one , two , three , go .\n"
     ]
    }
   ],
   "source": [
    "round_trip = tokenizers.en.detokenize(encoded)\n",
    "\n",
    "print('> This is human-readable text:')\n",
    "for line in round_trip.numpy():\n",
    "  print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69cd22e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is the text split into tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'[START]', b'astronomers', b'now', b'believe', b'that', b'every',\n",
       "  b'star', b'in', b'the', b'galaxy', b'has', b'a', b'planet', b',', b'and',\n",
       "  b'they', b'sp', b'##ec', b'##ulate', b'that', b'up', b'to', b'one',\n",
       "  b'fifth', b'of', b'them', b'have', b'an', b'earth', b'-', b'like',\n",
       "  b'planet', b'that', b'might', b'be', b'able', b'to', b'harbor', b'life',\n",
       "  b',', b'but', b'we', b'have', b'n', b\"'\", b't', b'seen', b'any', b'of',\n",
       "  b'them', b'.', b'[END]']                                                 ,\n",
       " [b'[START]', b'now', b'here', b'are', b'live', b'images', b'being',\n",
       "  b'pulled', b'straight', b'from', b'the', b'feed', b'.', b'[END]'] ,\n",
       " [b'[START]', b'so', b':', b'one', b',', b'two', b',', b'three', b',',\n",
       "  b'go', b'.', b'[END]']                                              ]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('> This is the text split into tokens:')\n",
    "tokens = tokenizers.en.lookup(encoded)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d417ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for pt_examples, en_examples in train_examples.batch(1024):\n",
    "  pt_tokens = tokenizers.pt.tokenize(pt_examples)\n",
    "  lengths.append(pt_tokens.row_lengths())\n",
    "\n",
    "  en_tokens = tokenizers.en.tokenize(en_examples)\n",
    "  lengths.append(en_tokens.row_lengths())\n",
    "  print('.', end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeddc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lengths = np.concatenate(lengths)\n",
    "\n",
    "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
    "plt.ylim(plt.ylim())\n",
    "max_length = max(all_lengths)\n",
    "plt.plot([max_length, max_length], plt.ylim())\n",
    "plt.title(f'Maximum tokens per example: {max_length}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d98bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=128\n",
    "def prepare_batch(pt, en):\n",
    "    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n",
    "    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    en = en[:, :(MAX_TOKENS+1)]\n",
    "    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (pt, en_inputs), en_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ccde1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a905ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab0472-d932-4b30-92b2-af5b6f4ab73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
