{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff0c5d4-d6d5-43d7-a207-6ad1f0bc1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349738d4-6bed-4eee-9bbe-3e1c592f0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list --export > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e009cb-c224-45f5-8458-fb793744a0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                               with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f33e01-2139-4a0a-a251-9b1afbe8effa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Examples in Portuguese:\n",
      "o problema é que nunca vivi lá um único dia .\n",
      "os astrónomos acreditam que cada estrela da galáxia tem um planeta , e especulam que até um quinto deles tem um planeta do tipo da terra que poderá ter vida , mas ainda não vimos nenhum deles .\n",
      "agora aqui temos imagens sendo extraídas em tempo real diretamente do feed ,\n",
      "\n",
      "> Examples in English:\n",
      "except , i 've never lived one day of my life there .\n",
      "astronomers now believe that every star in the galaxy has a planet , and they speculate that up to one fifth of them have an earth-like planet that might be able to harbor life , but we have n't seen any of them .\n",
      "now here are live images being pulled straight from the feed .\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  print('> Examples in Portuguese:')\n",
    "  for pt in pt_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "  print()\n",
    "\n",
    "  print('> Examples in English:')\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e7db8f-51fd-4ba4-892d-54ecaf1419ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip\n",
      "184801/184801 [==============================] - 1s 4us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.\\\\ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bedca44-5c0d-44b3-bc9c-1c704b5fbaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7049958f-17f9-4760-a71d-532c257a351a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['detokenize',\n",
       " 'get_reserved_tokens',\n",
       " 'get_vocab_path',\n",
       " 'get_vocab_size',\n",
       " 'lookup',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "216ccd38-5128-4e48-adc4-80511a1ddf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a batch of strings:\n",
      "except , i 've never lived one day of my life there .\n",
      "astronomers now believe that every star in the galaxy has a planet , and they speculate that up to one fifth of them have an earth-like planet that might be able to harbor life , but we have n't seen any of them .\n",
      "now here are live images being pulled straight from the feed .\n"
     ]
    }
   ],
   "source": [
    "print('> This is a batch of strings:')\n",
    "for en in en_examples.numpy():\n",
    "  print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29ff66d3-cacd-4f06-a5a3-9167f8a8807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a padded-batch of token IDs:\n",
      "[2, 1533, 13, 45, 9, 142, 243, 752, 103, 204, 74, 99, 183, 96, 15, 3]\n",
      "[2, 3946, 110, 321, 75, 198, 1452, 77, 71, 2662, 144, 37, 580, 13, 72, 83, 5848, 5939, 1970, 75, 130, 73, 103, 3339, 74, 124, 89, 111, 462, 14, 106, 580, 75, 242, 97, 264, 73, 3487, 183, 13, 87, 78, 89, 50, 9, 56, 464, 225, 74, 124, 15, 3]\n",
      "[2, 110, 137, 86, 301, 722, 222, 2404, 1473, 109, 71, 1559, 15, 3]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "\n",
    "print('> This is a padded-batch of token IDs:')\n",
    "for row in encoded.to_list():\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "598e3766-4bd0-43b1-b094-17e390fa2746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is human-readable text:\n",
      "except , i ' ve never lived one day of my life there .\n",
      "astronomers now believe that every star in the galaxy has a planet , and they speculate that up to one fifth of them have an earth - like planet that might be able to harbor life , but we have n ' t seen any of them .\n",
      "now here are live images being pulled straight from the feed .\n"
     ]
    }
   ],
   "source": [
    "round_trip = tokenizers.en.detokenize(encoded)\n",
    "\n",
    "print('> This is human-readable text:')\n",
    "for line in round_trip.numpy():\n",
    "  print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3e2b2f3-7dd7-4114-9634-927f1536da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is the text split into tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'[START]', b'except', b',', b'i', b\"'\", b've', b'never', b'lived',\n",
       "  b'one', b'day', b'of', b'my', b'life', b'there', b'.', b'[END]']   ,\n",
       " [b'[START]', b'astronomers', b'now', b'believe', b'that', b'every',\n",
       "  b'star', b'in', b'the', b'galaxy', b'has', b'a', b'planet', b',', b'and',\n",
       "  b'they', b'sp', b'##ec', b'##ulate', b'that', b'up', b'to', b'one',\n",
       "  b'fifth', b'of', b'them', b'have', b'an', b'earth', b'-', b'like',\n",
       "  b'planet', b'that', b'might', b'be', b'able', b'to', b'harbor', b'life',\n",
       "  b',', b'but', b'we', b'have', b'n', b\"'\", b't', b'seen', b'any', b'of',\n",
       "  b'them', b'.', b'[END]']                                                 ,\n",
       " [b'[START]', b'now', b'here', b'are', b'live', b'images', b'being',\n",
       "  b'pulled', b'straight', b'from', b'the', b'feed', b'.', b'[END]'] ]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('> This is the text split into tokens:')\n",
    "tokens = tokenizers.en.lookup(encoded)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff0e267f-d477-4e7a-a671-8a0ba4a0a8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for pt_examples, en_examples in train_examples.batch(1024):\n",
    "  pt_tokens = tokenizers.pt.tokenize(pt_examples)\n",
    "  lengths.append(pt_tokens.row_lengths())\n",
    "\n",
    "  en_tokens = tokenizers.en.tokenize(en_examples)\n",
    "  lengths.append(en_tokens.row_lengths())\n",
    "  print('.', end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97b38a-0da1-480f-83b6-15d87fb4da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lengths = np.concatenate(lengths)\n",
    "\n",
    "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
    "plt.ylim(plt.ylim())\n",
    "max_length = max(all_lengths)\n",
    "plt.plot([max_length, max_length], plt.ylim())\n",
    "plt.title(f'Maximum tokens per example: {max_length}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288fd869-4c74-4e22-9328-882722958628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
